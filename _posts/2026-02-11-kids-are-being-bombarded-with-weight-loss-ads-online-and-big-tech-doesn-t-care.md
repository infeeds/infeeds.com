---
layout: post
title: "Kids Are Being Bombarded With Weight Loss Ads Online, and Big Tech Doesn't Care"
description: "England's children's commissioner exposes how social media platforms profit from targeting young people with banned weight loss product ads despite regulations."
date: 2026-02-11 04:00:17 +0530
author: adam
image: 'https://images.unsplash.com/photo-1768697581060-52e2edbee7fa?q=80&w=2070'
video_embed:
tags: [news, tech]
tags_color: '#1f78b4'
---

Social media platforms are letting kids get hammered with ads for weight loss injections, diet pills, and other body-changing products. This isn't some minor oversight. These ads are literally banned, yet they're still showing up in young people's feeds every single day.

Dame Rachel de Souza, England's children's commissioner, just released a report that should make every parent's blood boil. Her team surveyed 2,000 teenagers between 13 and 17, and what they found was disturbing. Kids described being "bombarded" with content pushing them to change their bodies, lose weight, and fix their appearance. We're talking about weight loss injections, diet products, skin-lightening creams (some of which are illegal to sell in the UK), and ads for cosmetic procedures like lip fillers.

One theme kept coming up in the focus groups: this stuff is "unavoidable." You can't escape it. The algorithms have decided that insecurity sells, and they're serving it up to the most vulnerable audience possible.

## When Regulation Becomes Theater

Here's the frustrating part. The Online Safety Act exists. Ofcom is supposed to be enforcing it. There's even a Children's Code of Practice that's meant to protect kids from exactly this type of harmful content. Yet somehow, the ads keep coming.

Ofcom claims body stigma content is already covered under their codes as "non-designated content." They say platforms are required to protect children from it and act swiftly when they become aware of it. But if that's true, why are thousands of teenagers reporting they can't scroll through their feeds without seeing another ad telling them they're not good enough?

The gap between what [Technology](https://infeeds.com/tags/?tag=technology) companies promise and what they actually deliver has never been wider. Dr. Peter Macaulay from the University of Derby hit the nail on the head when he said ending advertising to children on social media is just a "necessary step," not a complete solution. We need actual platform accountability, better enforcement, and education that helps kids understand they're being manipulated.

## Profiting From Teen Insecurity

Let's be honest about what's happening here. Social media platforms have built entire [business](https://infeeds.com/tags/?tag=business) models around keeping users engaged, and nothing drives engagement quite like making people feel inadequate. Advertisers know this. Platform algorithms know this. And they're exploiting it for profit.

Dame Rachel didn't mince words. She called the situation "immensely damaging" to young people's self-esteem and said we can't keep accepting "an online world that profits from children's insecurities and constantly tells them they need to change or must be better."

She's pushing for amendments to the Online Safety Act that would create a clear duty of care for platforms to stop showing ads to children altogether. She also wants stronger regulation around online sales of age-restricted products and suggested the government might need to consider restricting children's access to some social media platforms entirely.

The government responded with the usual carefully worded statement about how the Online Safety Act was never meant to be the final word. They mentioned launching a national consultation on "bold measures" including potentially banning social media for under 16s. We've heard this song before.

## The Enforcement Problem

Ofcom insists it doesn't tolerate tech firms "prioritising engagement over children's online safety." But tolerating and actually stopping are two different things. The platforms face questioning, they issue statements about how seriously they take child safety, and then nothing fundamentally changes.

Instagram's Adam Mosseri gets hauled in for questioning about the impact on minors. TikTok continues expanding its data collection empire. Meanwhile, kids are still seeing ads for products designed to make them hate their bodies.

The real question isn't whether we have enough rules on paper. It's whether anyone with actual power gives enough of a damn to enforce them. Because right now, it looks like the answer is no, and an entire generation is paying the price with their mental health while tech giants count their advertising revenue.